{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda:9\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', device)\n",
    "\n",
    "# Hyperparameters\n",
    "random_seed = 0\n",
    "learning_rate = 0.001\n",
    "num_epochs = 500\n",
    "batch_size = 512\n",
    "\n",
    "# Model architecture parameters\n",
    "num_classes = 1\n",
    "num_features = 90 * 90\n",
    "num_latent = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_and_create_condition(mag_file_path, labels_linear_path, labels_nonlinear_path):\n",
    "    \"\"\"\n",
    "    Load magnetic data and create conditions based on linear and nonlinear labels.\n",
    "\n",
    "    Args:\n",
    "    - mag_file_path (str): Path to the magnetic data file.\n",
    "    - labels_linear_path (str): Path to the linear labels file.\n",
    "    - labels_nonlinear_path (str): Path to the nonlinear labels file.\n",
    "\n",
    "    Returns:\n",
    "    - filtered_mag_data (np.ndarray): Filtered magnetic data.\n",
    "    - filtered_condition (np.ndarray): Condition labels for the filtered data.\n",
    "    - nlinear (int): Number of linear samples.\n",
    "    - nnonlinear (int): Number of nonlinear samples.\n",
    "    - nentire (int): Total number of filtered samples.\n",
    "    \"\"\"\n",
    "    # Load magnetic data\n",
    "    mag_data = np.loadtxt(mag_file_path)\n",
    "    \n",
    "    # Load labels of linear and nonlinear images\n",
    "    labels_linear = np.loadtxt(labels_linear_path)\n",
    "    labels_nonlinear = np.loadtxt(labels_nonlinear_path)\n",
    "    \n",
    "    # Initialize condition labels as 2 (indicating unclassified)\n",
    "    condition = np.full(len(mag_data), 2)\n",
    "    \n",
    "    # Set linear labels to 1\n",
    "    tag_linear = [int(x - 1) for x in labels_linear]\n",
    "    condition[tag_linear] = 1\n",
    "    \n",
    "    # Set nonlinear labels to 0\n",
    "    tag_nonlinear = [int(x - 1) for x in labels_nonlinear]\n",
    "    condition[tag_nonlinear] = 0\n",
    "    \n",
    "    # Filter out unclassified data (condition == 2)\n",
    "    mask = condition != 2\n",
    "    filtered_mag_data = mag_data[mask]\n",
    "    filtered_condition = condition[mask]\n",
    "    \n",
    "    # Reshape and transpose the filtered magnetic data\n",
    "    nsample = filtered_mag_data.shape[0]\n",
    "    filtered_mag_data = filtered_mag_data.reshape((nsample, 90, 90))\n",
    "    filtered_mag_data = filtered_mag_data.transpose(0, 2, 1)\n",
    "    filtered_mag_data = filtered_mag_data[:, np.newaxis, :, :]\n",
    "    \n",
    "    # Number of linear and nonlinear samples\n",
    "    nlinear = len(labels_linear)\n",
    "    nnonlinear = len(labels_nonlinear)\n",
    "    nentire = nlinear + nnonlinear\n",
    "    \n",
    "    return filtered_mag_data, filtered_condition, nlinear, nnonlinear, nentire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load magnetic data, condition labels, and orientation data\n",
    "mag_data, cond, nlinear, nnonlinear, nentire = load_data_and_create_condition(\n",
    "    'TXTData/TXTDiff.txt', 'Labels/DIFF_linear.txt', 'Labels/DIFF_nonlinear.txt'\n",
    ")\n",
    "\n",
    "# Load angle (orientation) data\n",
    "angle = np.loadtxt('Labels/Orientations.txt')\n",
    "\n",
    "# Set angle to 0 for nonlinear conditions\n",
    "angle[cond == 0] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and standardize the magnetic data\n",
    "mean_value = np.mean(mag_data, axis=0)\n",
    "std_dev = np.std(mag_data, axis=0)\n",
    "mag_std = ((mag_data - mean_value) / std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MagSet(Dataset):\n",
    "    def __init__(self, data, labels, angles):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - data (np.ndarray): The magnetic data.\n",
    "        - labels (np.ndarray): The condition labels.\n",
    "        - angles (np.ndarray): The angle data.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.angles = angles\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "        - int: The number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - index (int): Index of the sample to retrieve.\n",
    "\n",
    "        Returns:\n",
    "        - dict: A dictionary containing the data, label, and angle of the sample.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'data': self.data[index],\n",
    "            'label': self.labels[index],\n",
    "            'angle': self.angles[index]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "test_size = 0.1  # Proportion of the dataset to include in the test split\n",
    "random_seed = 42  # Seed for random number generator for reproducibility\n",
    "\n",
    "# Perform the train-test split\n",
    "train_data, test_data, train_labels, test_labels, train_angles, test_angles = train_test_split(\n",
    "    mag_std, cond, angle, test_size=test_size, random_state=random_seed\n",
    ")\n",
    "\n",
    "# Create dataset instances for training and testing sets\n",
    "train_dataset = MagSet(train_data, train_labels, train_angles)\n",
    "test_dataset = MagSet(test_data, test_labels, test_angles)\n",
    "\n",
    "# Create data loaders for training set\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Convert test data, labels, and angles from NumPy arrays to PyTorch tensors\n",
    "test_data_t = torch.from_numpy(test_data).float()\n",
    "test_labels_t = torch.from_numpy(test_labels).long()\n",
    "test_angles_t = torch.from_numpy(test_angles).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMD calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(source,target,kernel_mul = 2, kernel_num = 5, fix_sigma = None):\n",
    "    n_samples = int(source.size()[0])+int(target.size()[0])\n",
    "    total = torch.cat([source,target],dim = 0)\n",
    "    total0 = total.unsqueeze(0).expand(int(total.size(0)),\\\n",
    "                                      int(total.size(0)),\\\n",
    "                                      int(total.size(1)))\n",
    "    total1 = total.unsqueeze(1).expand(int(total.size(0)),\\\n",
    "                                      int(total.size(0)),\\\n",
    "                                      int(total.size(1)))\n",
    "    L2_distance = ((total0-total1) **2).sum(2)\n",
    "    if fix_sigma:\n",
    "        bandwidth = fix_sigma\n",
    "    else:\n",
    "        bandwidth = torch.sum(L2_distance.data)/(n_samples**2 - n_samples)\n",
    "    bandwidth /= kernel_mul ** (kernel_num//2)\n",
    "    bandwidth_list = [bandwidth * (kernel_mul **i) for i in range(kernel_num)]\n",
    "    kernel_val = [torch.exp(-L2_distance/bandwidth_temp) for\\\n",
    "                 bandwidth_temp in bandwidth_list]\n",
    "    return sum(kernel_val)\n",
    "\n",
    "def mmd(source,target,kernel_mul = 2, kernel_num = 5, fix_sigma = None):\n",
    "    batch_size = int(source.size()[0])\n",
    "    kernels = gaussian_kernel(source,target,\n",
    "                             kernel_mul = kernel_mul,\n",
    "                             kernel_num = kernel_num,\n",
    "                             fix_sigma = fix_sigma)\n",
    "    XX = kernels[:batch_size, :batch_size]\n",
    "    YY = kernels[batch_size:, batch_size:]\n",
    "    XY = kernels[:batch_size, batch_size:]\n",
    "    YX = kernels[batch_size:, :batch_size]\n",
    "    loss = torch.mean(XX+YY-XY-YX)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CVAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalVariationalAutoencoder(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_latent):\n",
    "        super(ConditionalVariationalAutoencoder, self).__init__()\n",
    "\n",
    "        # Encoder layers\n",
    "        self.enc_conv_1 = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(6, 6), stride=(2, 2), padding=0)\n",
    "        self.enc_conv_2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(4, 4), stride=(2, 2), padding=0)\n",
    "        self.enc_conv_3 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
    "        self.enc_conv_4 = torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
    "        self.enc_conv_5 = torch.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
    "        self.z = torch.nn.Linear(256 * 2 * 2, num_latent)\n",
    "\n",
    "        # Decoder layers\n",
    "        self.dec_linear_1 = torch.nn.Linear(num_latent + 2, 256 * 2 * 2)\n",
    "        self.dec_conv_1 = torch.nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
    "        self.dec_conv_2 = torch.nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=(3, 3), stride=(2, 2), padding=0)\n",
    "        self.dec_conv_3 = torch.nn.ConvTranspose2d(in_channels=64, out_channels=32, kernel_size=(4, 4), stride=(2, 2), padding=2)\n",
    "        self.dec_conv_4 = torch.nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=(4, 4), stride=(2, 2), padding=2)\n",
    "        self.dec_conv_5 = torch.nn.ConvTranspose2d(in_channels=16, out_channels=1, kernel_size=(5, 5), stride=(3, 3), padding=1)\n",
    "\n",
    "    def encoder(self, features, targets, angles):\n",
    "        \"\"\"\n",
    "        Encode the input features with conditions.\n",
    "\n",
    "        Args:\n",
    "        - features (torch.Tensor): Input feature tensor.\n",
    "        - targets (torch.Tensor): Target tensor.\n",
    "        - angles (torch.Tensor): Angle tensor.\n",
    "\n",
    "        Returns:\n",
    "        - torch.Tensor: Encoded latent representation.\n",
    "        \"\"\"\n",
    "        ones = torch.ones(features.size(0), 1, features.size(2), features.size(3), dtype=features.dtype).to(features.device)\n",
    "        target_matrix = ones * targets.view(-1, 1, 1, 1)\n",
    "        angle_matrix = ones * angles.view(-1, 1, 1, 1)\n",
    "        \n",
    "        # Concatenate features with target and angle matrices\n",
    "        x = torch.cat((features, target_matrix, angle_matrix), dim=1).float()\n",
    "        \n",
    "        # Pass through convolutional layers with LeakyReLU activations\n",
    "        x = F.leaky_relu(self.enc_conv_1(x))\n",
    "        x = F.leaky_relu(self.enc_conv_2(x))\n",
    "        x = F.leaky_relu(self.enc_conv_3(x))\n",
    "        x = F.leaky_relu(self.enc_conv_4(x))\n",
    "        x = F.leaky_relu(self.enc_conv_5(x))\n",
    "        \n",
    "        # Flatten and pass through the linear layer to get the latent representation\n",
    "        encoded = self.z(x.view(-1, 256 * 2 * 2))\n",
    "        return encoded\n",
    "\n",
    "    def decoder(self, encoded, targets, angles):\n",
    "        \"\"\"\n",
    "        Decode the latent representation back to the input space.\n",
    "\n",
    "        Args:\n",
    "        - encoded (torch.Tensor): Encoded latent representation.\n",
    "        - targets (torch.Tensor): Target tensor.\n",
    "        - angles (torch.Tensor): Angle tensor.\n",
    "\n",
    "        Returns:\n",
    "        - torch.Tensor: Decoded tensor.\n",
    "        \"\"\"\n",
    "        # Concatenate encoded representation with targets and angles\n",
    "        encoded = torch.cat((encoded, targets.view(-1, 1), angles.view(-1, 1)), dim=1).float()\n",
    "        \n",
    "        # Pass through linear layer and reshape\n",
    "        x = F.leaky_relu(self.dec_linear_1(encoded))\n",
    "        x = x.view(-1, 256, 2, 2)\n",
    "        \n",
    "        # Pass through transposed convolutional layers with LeakyReLU activations\n",
    "        x = F.leaky_relu(self.dec_conv_1(x))\n",
    "        x = F.leaky_relu(self.dec_conv_2(x))\n",
    "        x = F.leaky_relu(self.dec_conv_3(x))\n",
    "        x = F.leaky_relu(self.dec_conv_4(x))\n",
    "        decoded = self.dec_conv_5(x)\n",
    "\n",
    "        return decoded\n",
    "\n",
    "    def forward(self, features, targets, angles):\n",
    "        \"\"\"\n",
    "        Forward pass through the encoder and decoder.\n",
    "\n",
    "        Args:\n",
    "        - features (torch.Tensor): Input feature tensor.\n",
    "        - targets (torch.Tensor): Target tensor.\n",
    "        - angles (torch.Tensor): Angle tensor.\n",
    "\n",
    "        Returns:\n",
    "        - (torch.Tensor, torch.Tensor): Encoded latent representation and decoded tensor.\n",
    "        \"\"\"\n",
    "        encoded = self.encoder(features, targets, angles)\n",
    "        decoded = self.decoder(encoded, targets, angles)\n",
    "        return encoded, decoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CVAE initalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# Initialize the Conditional Variational Autoencoder model\n",
    "model = ConditionalVariationalAutoencoder(num_features, num_latent)\n",
    "\n",
    "# Move the model to the specified device (e.g., GPU)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Set the learning rate decay factor\n",
    "gamma = 0.995 \n",
    "\n",
    "# Initialize the learning rate scheduler\n",
    "scheduler = ExponentialLR(optimizer, gamma=gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CVAE training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()  # Record start time\n",
    "losses = []\n",
    "losses_mmd = []\n",
    "losses_pred = []\n",
    "\n",
    "losses_t = []\n",
    "losses_mmd_t = []\n",
    "losses_pred_t = []\n",
    "\n",
    "# Move model to device once\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    epoch_mmd = 0.0\n",
    "    epoch_pred = 0.0\n",
    "    total_batch = 0\n",
    "    \n",
    "    model.train()  # Set the model to training mode\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        features = batch['data'].to(device)\n",
    "        targets = batch['label'].to(device)\n",
    "        angles = batch['angle'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        encoded, decoded = model(features, targets, angles)\n",
    "        decoded = decoded.to(torch.float64)\n",
    "        \n",
    "        sam_num = decoded.shape[0]\n",
    "        true_samples = Variable(torch.randn(sam_num, num_latent), requires_grad=False).to(device)\n",
    "        \n",
    "        # Calculate losses\n",
    "        loss_pred = F.mse_loss(decoded, features)\n",
    "        loss_mmd = mmd(encoded, true_samples)\n",
    "        loss = loss_mmd + loss_pred\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_mmd += loss_mmd.item()\n",
    "        epoch_pred += loss_pred.item()\n",
    "        total_batch += 1\n",
    "        \n",
    "        # Backward pass and parameter update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Calculate average losses\n",
    "    average_loss = epoch_loss / total_batch\n",
    "    average_mmd = epoch_mmd / total_batch\n",
    "    average_pred = epoch_pred / total_batch\n",
    "    \n",
    "    losses.append(average_loss)\n",
    "    losses_mmd.append(average_mmd)\n",
    "    losses_pred.append(average_pred)\n",
    "    \n",
    "    # Update the learning rate scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        encoded, decoded = model(test_data_t.to(device), test_labels_t.to(device), test_angles_t.to(device))\n",
    "        sam_num = decoded.shape[0]\n",
    "        true_samples = Variable(torch.randn(sam_num, num_latent), requires_grad=False).to(device)\n",
    "        \n",
    "        loss_pred_t = F.mse_loss(decoded, test_data_t.to(device))\n",
    "        loss_mmd_t = mmd(encoded, true_samples)\n",
    "        loss_t = loss_mmd_t + loss_pred_t\n",
    "        \n",
    "        losses_t.append(loss_t.item())\n",
    "        losses_mmd_t.append(loss_mmd_t.item())\n",
    "        losses_pred_t.append(loss_pred_t.item())\n",
    "    \n",
    "    # Print results for each epoch\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs} | Loss: {average_loss:.4f} | '\n",
    "          f'Pred Loss: {average_pred:.4f} | MMD Loss: {average_mmd:.4f} | '\n",
    "          f'Test Loss: {loss_t.item():.4f} | Test MMD: {loss_mmd_t.item():.4f} | '\n",
    "          f'Test Pred Loss: {loss_pred_t.item():.4f}')\n",
    "\n",
    "# Training time\n",
    "print(f'Training time: {time.time() - start_time:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'Generator_CVAE/CVAE.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training losses\n",
    "plt.figure()\n",
    "plt.plot(losses, label='Loss')\n",
    "plt.plot(losses_mmd, label='Loss_mmd')\n",
    "plt.plot(losses_pred, label='Loss_pred')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training Losses')\n",
    "plt.show()\n",
    "\n",
    "# Plot testing losses\n",
    "plt.figure()\n",
    "plt.plot(losses_t, label='Loss')\n",
    "plt.plot(losses_mmd_t, label='Loss_mmd')\n",
    "plt.plot(losses_pred_t, label='Loss_pred')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Testing Losses')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
